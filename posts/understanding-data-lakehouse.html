<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><link rel="icon shortcut" type="image/png" href="https://ttyfky.github.io/logo.png"/><meta property="og:title" content="Data Lakehouse を理解する"/><meta property="og:url" content="https://ttyfky.github.io/posts/understanding-data-lakehouse"/><meta name="twitter:card" content="summary"/><meta property="og:site" content="ttyfky.github.io"/><meta property="og:image" content="https://ttyfky.github.io/og.png"/><meta name="description" content="Data Lakehouse についての概要説明とクラウドベンダーごとのアプローチについて"/><meta property="og:description" content="Data Lakehouse についての概要説明とクラウドベンダーごとのアプローチについて"/><link rel="canonical" href="https://ttyfky.github.io/posts/understanding-data-lakehouse"/><title>Data Lakehouse を理解する</title><meta name="next-head-count" content="13"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin /><link rel="preload" href="/_next/static/css/bddaf1d3a9061156.css" as="style"/><link rel="stylesheet" href="/_next/static/css/bddaf1d3a9061156.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-d7b038a63b619762.js" defer=""></script><script src="/_next/static/chunks/framework-5f4595e5518b5600.js" defer=""></script><script src="/_next/static/chunks/main-c586b89e07064d4a.js" defer=""></script><script src="/_next/static/chunks/pages/_app-3b95a20da9395822.js" defer=""></script><script src="/_next/static/chunks/880-abd47264bbbe8a7a.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bslug%5D-ee156daee2963af1.js" defer=""></script><script src="/_next/static/Omp03XJcnyDL6FY7ABKPf/_buildManifest.js" defer=""></script><script src="/_next/static/Omp03XJcnyDL6FY7ABKPf/_ssgManifest.js" defer=""></script><script src="/_next/static/Omp03XJcnyDL6FY7ABKPf/_middlewareManifest.js" defer=""></script><style data-href="https://fonts.googleapis.com/css2?family=Inter:wght@400;700&display=swap">@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcCO3FwrK3iLTeHuS_fvQtMwCp50KnMw2boKoduKmMEVuLyfMZs.woff) format('woff')}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcCO3FwrK3iLTeHuS_fvQtMwCp50KnMw2boKoduKmMEVuFuYMZs.woff) format('woff')}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}</style></head><body><div id="__next" data-reactroot=""><header class="site-header"><div class="content-wrapper"><div class="site-header__inner"><a class="site-header__logo-link" href="/"><img src="/avatars/profile.jpg" alt="ttyfky.github.io" class="site-header__logo-img"/><h3 class="site-header__title">ttyfky.github.io</h3></a><div class="site-header__links"><a class="site-header__link" href="/">Home</a><a class="site-header__link" href="/bio">Bio</a></div></div></div></header><div class="content-wrapper"><article class="posts__body"><h1>Data Lakehouse を理解する</h1><div class="posts__date">2022-04-10<ul class="tag__ul"><li class="tag__li"><a class="tag__link" href="/tags/data">#data</a></li><li class="tag__li"><a class="tag__link" href="/tags/dwh">#dwh</a></li><li class="tag__li"><a class="tag__link" href="/tags/lakehouse">#lakehouse</a></li></ul></div><br/><div><h1 id="overview">Overview</h1>
<p>本記事では Data Lakehouse という概念についての調査メモ。
Lakehouse は Databrics が提唱している概念のようで、特定のベンダーが進めている話ならまだ重要視するほどでもなさそうだが
<a href="http://cidrdb.org/cidr2021/papers/cidr2021_paper17.pdf" target="_blank" rel="noopener noreferrer">論文</a>としても出ており、
GCP でも紹介され(<a href="https://cloud.google.com/blog/ja/products/data-analytics/open-data-lakehouse-on-google-cloud" target="_blank" rel="noopener noreferrer">2021-10-29</a>,
<a href="https://cloud.google.com/blog/ja/products/data-analytics/google-cloud-data-cloud-summit" target="_blank" rel="noopener noreferrer">2022-04-05</a>)、
つい最近発表された <a href="https://cloud.google.com/bigquery/docs/biglake-intro" target="_blank" rel="noopener noreferrer">BigLake</a>
というプロダクトが作られる元となった考え方のようなので 2022-04 時点で Lakehouse はどういったものを指しどんな課題を解こうとしているのかということを整理する。</p>
<h2 id="tldr">TL;DR</h2>
<ul>
<li>これまでのデータ処理基盤は<a href="building-data-platform">以前触れた</a>通り、Datalake -&gt; Data Warehouse(DWH) -&gt; Datamart のようなアーキテクチャが一般的</li>
<li>従来の DWH や Datalake では分析や機械学習を行うためにはそれぞれ一定の制限がある</li>
<li>Data Lakehouse は DWH や Datalake の良い点を活かして既存の制限を解決するアプローチ</li>
</ul>
<p>本記事では論文 <a href="http://cidrdb.org/cidr2021/papers/cidr2021_paper17.pdf" target="_blank" rel="noopener noreferrer">Lakehouse: A New Generation of Open Platforms that Unify Data Warehousing and Advanced Analytics</a> (Ref1) での議論をベースに整理する。</p>
<h1 id="従来のデータ分析基盤について">従来のデータ分析基盤について</h1>
<p>従来のデータ活用においては RDB などから必要なデータを取り出して構造化データを DWH として取り込む形が早くから始まった。<br/>
DWH は BI アプリケーションから扱いやすいが、 ML でのデータ活用ではテキスト、画像、動画、音声などの非構造化データを扱う需要があり、 DWH でのデータの持ち方では扱いづらい場面がある。</p>
<p>そこで、生データを扱い非構造化データの保持も可能なものとして Datalake という層を作り、非構造化データを扱う処理は Datalake を利用することで処理が可能となった。
しかし、Datalake はデータの管理が複雑で、トランザクション、データ品質の保証・一貫性・分離性などが欠如しており、データ処理パイプラインにおいてデータの追加と読み取りの同時実行などが難しいという制限がある。</p>
<p><img src="https://databricks.com/wp-content/uploads/2020/01/data-lakehouse-new-1024x538.png" alt="Datalakehouse Image"/><br/>
(Ref2 より)</p>
<h2 id="従来のデータウェアハウスアーキテクチャの課題">従来のデータウェアハウスアーキテクチャの課題</h2>
<ul>
<li>DWH は構造化データの利用には良いが非構造化データの利用には向いていない</li>
<li>機械学習を行う場合非構造化データを用いる場合もあるため DWH だけでは不十分</li>
<li>生データが前提の Datalake の概念によりではあらゆるデータを保持できるようになったが、データ処理パイプラインの作り方に制限がある
<ul>
<li>トランザクションは管理できない</li>
<li>データ品質の保証の仕組みは無視されがち
<ul>
<li>データの重複など</li>
</ul>
</li>
</ul>
</li>
<li>異なる DWH にデータが有る場合にデータの移動が必要となる</li>
<li>Datalake と DWH を分離したアーキテクチャでの複雑性
<ul>
<li>それぞれでセマンティクスの異なるデータタイプ</li>
<li>SQL の方言の違い</li>
<li>データのスキーマが異なる</li>
</ul>
</li>
<li>データの鮮度</li>
</ul>
<h1 id="lakehouse">Lakehouse</h1>
<h2 id="lakehouse-の目指すもの">Lakehouse の目指すもの</h2>
<p>Lakehouse は、Datalake と Data Warehouse の優れた部分を組み合わせた、新しくオープンなアーキテクチャである。標準化されたシステムによって実現され DWH と同様のデータ構造とデータマネジメント機構を備えており、 Datalake のように安価なストレージに直接アクセスすることができる。</p>
<ul>
<li>Datalake において信頼できるデータマネジメントが可能
<ul>
<li>Datalake のレイヤーにおいてもトランザクションや ID の管理が可能</li>
</ul>
</li>
<li>ML とデータサイエンスをサポート
<ul>
<li>ML の仕組みがファイルの直接読み込む事が可能</li>
<li>DataFrames のようにデータを抽象化して操作が可能</li>
</ul>
</li>
<li>SQL のパフォーマンス
<ul>
<li>Parquet や ORC のようなデータフォーマットを扱える</li>
<li>直接データアクセス可能</li>
</ul>
</li>
</ul>
<h3 id="lakehouse-が持つべきと考えられる機能">Lakehouse が持つべきと考えられる機能</h3>
<ul>
<li>トランザクションのサポート
<ul>
<li>同時にデータの読み書きを行うデータパイプラインを許容するため ACID トランザクションをサポートし、特に SQL を用いたケースで複数のデータの読み書きがあったとしても一貫性の維持が可能</li>
</ul>
</li>
<li>スキーマ適用及びガバナンス可能
<ul>
<li>スタースキーマ、スノーフレークスキーマのようにデータウェアハウスのスキーマアーキテクチャをサポートすることでレイクハウスはスキーマの適用・進化をサポート</li>
<li>システムはデータの完全性を保証し、頑健性のあるガバナンス機能や監査機構が可能</li>
</ul>
</li>
<li>BI のサポート
<ul>
<li>ソースデータに直接アクセスして BI が可能で、遅延を減らしデータの鮮度が保つ</li>
<li>データレイクとデータウェアハウスでデータの二重持ちする必要が無いためコストを低減</li>
</ul>
</li>
<li>計算リソースとストレージの分離
<ul>
<li>ストレージと計算リソースが異なるクラスターを用いることで同時接続ユーザー数の増加やデータ量の増加に応じてシステムをスケールアウト</li>
</ul>
</li>
<li>オープンなストレージフォーマット
<ul>
<li>使用するストレージフォーマットは Parquet のようにオープンかつ標準化されたもの
<ul>
<li>TensorFlow や Spark MLlib は Parquet を読むことができるため、メタデータにクエリしどの Parquet ファイルを読むかの管理を行うだけで良い</li>
</ul>
</li>
<li>機械学習、Python/R ライブラリのように多くのツールやエンジンに対する API を提供しデータへの直接アクセスが可能</li>
</ul>
</li>
<li>様々なデータタイプをサポート
<ul>
<li>画像、動画、音声、準構造化データ、テキストを含む、新たなデータアプリケーションで必要となる様々なデータタイプの分析・精錬・格納に利用</li>
</ul>
</li>
<li>様々なワークロードをサポート
<ul>
<li>データサイエンス、機械学習、SQL や分析に対応</li>
<li>全て同じデータリポジトリを使用</li>
</ul>
</li>
<li>エンドツーエンドのストリーミング
<ul>
<li>ストリーミングのサポートによりリアルタイムデータ処理専用のアプリケーションを別に持つ必要がなくなる</li>
</ul>
</li>
</ul>
<h2 id="lakehouse-のアーキテクチャ">Lakehouse のアーキテクチャ</h2>
<p>Lakehouse は低コストで直接アクセス可能なストレージに基づくデータ管理システムであり、ACID トランザクションやインデックスなど従来の分析型 DBMS の管理・パフォーマンス機能も備えるようにしたい。
データの直接アクセスが可能なためデータの独立性は放棄する。</p>
<p>データはオブジェクトストレージ上で Parquet のような標準化されたフォーマットで持ち、トランザクションのサポートのためにメタデータレイヤーを持つ。
DataFrames を利用できる API を持つことで R や Python の Pandas との連携が簡単にでき、また Spark SQL では宣言的に利用でき遅延実行できる。</p>
<figure>
<img src="lakehouse-architecture-sample.png" alt="Lakehouseのアーキテクチャイメージ図"/>
</figure>
(Ref1 より引用）
<h3 id="データ管理のためのメタデータレイヤー">データ管理のためのメタデータレイヤー</h3>
<p>Lakehouse として最初に必要になるの Datalake ストレージのためのはメタデータレイヤーである。
具体的には、<a href="https://iceberg.apache.org/" target="_blank" rel="noopener noreferrer">Apache Iceberg</a> や <a href="https://hudi.apache.org/" target="_blank" rel="noopener noreferrer">Apache Hudi</a>、<a href="https://delta.io/" target="_blank" rel="noopener noreferrer">Delta Lake</a> などの
ファイルストレージ上に保存された Parquet/ORC フォーマットのファイルの管理を可能にするメカニズムを用いて、ACID トランザクションやバージョン管理などを可能にする。</p>
<p>この領域は比較的新しく、今後更に最適化が進む可能性がある。挙げられたフレームワークもトランザクションログは 1 テーブルのみをサポートしているなど、高遅延であったり、ファイルが大きくなるといったオブジェクトストレージの制限の影響を受けている。</p>
<h3 id="lakehouse-における-sql-パフォーマンス">Lakehouse における SQL パフォーマンス</h3>
<p>Datalake における最も大きな技術的な課題は、データの独立性を放棄した(直接アクセス可能なファイルで管理するため)上でどの様に SQL の最高のパフォーマンスを実現するのかという点である。</p>
<p>SQL パフォーマンスを良くするアプローチとしては以下が考えられる。</p>
<ul>
<li>Caching
<ul>
<li>トランザクションのメタデータを処理ノードの SSD や RAM に置く</li>
</ul>
</li>
<li>補助データ
<ul>
<li>カラム毎の最大最小値の統計情報を各ファイルごとに持つ</li>
<li>Bloom filter ベースのインデックスを構築し選択した列でデータをスキップできるようにする</li>
</ul>
</li>
<li>データの配置
<ul>
<li>Z-order<sup><a href="/posts/understanding-data-lakehouse#user-content-fn-zorder">1</a></sup> などを用いてデータの局所性を表現する</li>
</ul>
</li>
</ul>
<p>直接アクセス可能で長期的にデータの保存が可能かつ高パフォーマンスな Lakehouse の仕組みの設計は現状も課題である。
将来的にはこのユースケースに特化した新たなデータフォーマットの自体が必要かもしれないが、それを抜きにしてもここで上げたパフォーマンスを良くするための要素はいずれも向上の余地はある。</p>
<h1 id="クラウドベンダーにおける-lakehouse">クラウドベンダーにおける Lakehouse</h1>
<h2 id="biglake---gcp">BigLake - GCP</h2>
<p>Lakehouse の調査をするきっかけになったのは Apr2022 の Google Data Cloud Summit 先駆けて <a href="https://cloud.google.com/blog/ja/products/data-analytics/google-cloud-data-cloud-summit" target="_blank" rel="noopener noreferrer">BigLake についての記事</a>が発表されたからだった。</p>
<p>記事の執筆時点では Preview 版であるが、 <a href="https://cloud.google.com/bigquery/docs/biglake-intro" target="_blank" rel="noopener noreferrer">Introduction to BigLake tables</a> に BigLake の説明がある。<br/>
簡単に表現すると BigLake は BigQuery External Table 機能の拡張のようなものだ。
基本的には BigQuery (以下 BQ) をインターフェイスとして、GCS や S3 などのオブジェクトストレージへアクセスするが、BQ がアクセスマネジメントを抽象化する。
つまり、ユーザーのアクセス権限は BQ のテーブルに対してのみ考えたら良く、BQ を超えたレイヤー(i.e. 外部のストレージ)に対するアクセス権限をユーザーは意識する必要がない。</p>
<p><img src="https://cloud.google.com/bigquery/images/biglake_arch.png" alt="BigLake Image"/><br/>
(Ref4 より引用）</p>
<p>現状はトランザクションへの言及などはなく、非構造化データとの連携もこの形で行いやすくなるとも思えないため、自分の理解ではこれまで触れてきた Lakehouse の目標には届いていない印象。
BQ の場合はそもそも Dataflow や Serverless Spark 等の ETL のレイヤーから低遅延の Storage API を提供してデータを素早くよしなに扱って欲しいという思惑があるかもしれない。</p>
<p>また、BQ は<a href="https://cloud.google.com/bigquery/docs/reference/standard-sql/transactions" target="_blank" rel="noopener noreferrer">トランザクションのサポート</a>が Preview レベルではあるが開始されているため、
今後外部テーブル関しての操作自体<sup><a href="/posts/understanding-data-lakehouse#user-content-fn-bq-export">2</a></sup>やトランザクション機能の追加があると Lakehouse の実現に近づくと思う。</p>
<p><a href="https://cloud.google.com/blog/ja/products/data-analytics/getting-started-with-new-table-formats-on-dataproc" target="_blank" rel="noopener noreferrer">Dataproc の新しいテーブル形式を使ってみる</a>や
<a href="https://cloud.google.com/blog/topics/developers-practitioners/how-build-open-cloud-datalake-delta-lake-presto-dataproc-metastore" target="_blank" rel="noopener noreferrer">How to build an open cloud datalake with Delta Lake, Presto &amp; Dataproc Metastore</a> などの記事にもある通り、
GCP 上での Delta Lake や Apache Iceberg の利用も可能だが、Dataproc (i.g. Hadoop) で Spark の利用が前提になっている。
Spark/Hadoop クラスタの運用は手間がかかるので、Serverless Spark が GA とったことはこれらのフレームワークを利用する上でも良い発展に思える。</p>
<h2 id="delta-lake---azure">Delta Lake - Azure</h2>
<p>Azure は Databrics と連携しており、Delta Lake についての<a href="https://docs.microsoft.com/ja-jp/azure/databricks/delta/" target="_blank" rel="noopener noreferrer">厚めのドキュメント</a>がある。<br/>
日本語で細かく説明したドキュメントは貴重なので一読の価値あり。</p>
<p><img src="https://docs.microsoft.com/ja-jp/azure/databricks/scenarios/media/what-is-azure-databricks/azure-databricks-overview.png" alt="Azure Databrics"/><br/>
(Ref6 より引用）</p>
<h2 id="aws">AWS</h2>
<p>AWS では <a href="https://aws.amazon.com/blogs/big-data/build-a-lake-house-architecture-on-aws/" target="_blank" rel="noopener noreferrer">Build a Lake House Architecture on AWS</a>、
<a href="https://aws.amazon.com/blogs/big-data/harness-the-power-of-your-data-with-aws-analytics/" target="_blank" rel="noopener noreferrer">Harness the power of your data with AWS Analytics</a>、
<a href="https://aws.amazon.com/blogs/architecture/how-to-accelerate-building-a-lake-house-architecture-with-aws-glue/" target="_blank" rel="noopener noreferrer">How to Accelerate Building a Lake House Architecture with AWS Glue</a>
など、AWS 上で Lakehouse を構築する方法を説明した記事が多く見つかった。</p>
<p>中でも <a href="https://aws.amazon.com/lake-formation/" target="_blank" rel="noopener noreferrer">AWS Lake Formation</a> は Lakehouse 構築のためのキーとなるプロダクトに見え、S3 のファイルに対して ACID トランザクションを実現したりクエリによるアクセス速度の向上を実現でき、
論文中で言及していたデータ管理のためのメタデータレイヤーを構築を可能にする。</p>
<p><img src="https://d2908q01vomqb2.cloudfront.net/b6692ea5df920cad691c20319a6fffd7a4a766b8/2020/12/08/harness-the-power-4.jpg" alt="AWS Lakehouse Architecture"/><br/>
(Ref9 より引用）</p>
<p><img src="https://d2908q01vomqb2.cloudfront.net/fc074d501302eb2b93e2554793fcaf50b3bf7291/2021/08/18/Fig2-Glue.png" alt="AWS Lakehouse Architecture"/>
(Ref10 より引用）</p>
<h1 id="終わりに">終わりに</h1>
<p>本記事では Data Lakehouse の調査を行った。</p>
<p>Lakehouse は従来の DWH や Datalake の仕組みに存在した制限を乗り越えるためのアプローチである。<br/>
Datalake は ACID トランザクションやインデックス等の DBMS のような仕組みを用いていたり、Parquet/OCR のような標準化されたファイルフォーマットを用いての直接ファイルアクセスが可能なことが期待される。</p>
<p>各クラウドベンダーもそれぞれ Lakehouse に言及しており、今後のデータ処理基盤構築では意識していくべきものに思える。
Lakehouse の実現には Dalta Lake のようなフレームワークを用いるか、各クラウドベンダーが提供するプロダクトを用いると良さそうだが、ベンダー毎に実現可能なレベル感はまだ一定ではなく、今後の継続的なアップデートが期待される。</p>
<h1 id="references">References</h1>
<ol>
<li><a href="http://cidrdb.org/cidr2021/papers/cidr2021_paper17.pdf" target="_blank" rel="noopener noreferrer">Lakehouse: A New Generation of Open Platforms that Unify Data Warehousing and Advanced Analytics</a></li>
<li><a href="https://databricks.com/blog/2020/01/30/what-is-a-data-lakehouse.html" target="_blank" rel="noopener noreferrer">What Is a Lakehouse?</a></li>
<li><a href="https://cloudonair.withgoogle.com/events/summit-data-cloud-2022/watch?talk=s_databricks" target="_blank" rel="noopener noreferrer">Rise of the Data Lakehouse in Google Cloud</a></li>
<li><a href="https://cloud.google.com/bigquery/docs/biglake-intro" target="_blank" rel="noopener noreferrer">Introduction to BigLake tables</a></li>
<li><a href="https://cloudonair.withgoogle.com/events/summit-data-cloud-2022/watch?talk=vod_da1_s1_big_lake" target="_blank" rel="noopener noreferrer">BigLake: Unify data warehouses and lakes with Google Cloud</a></li>
<li><a href="https://docs.microsoft.com/ja-jp/azure/databricks/scenarios/what-is-azure-databricks-ws" target="_blank" rel="noopener noreferrer">Databricks Data Science &amp; Engineering とは</a></li>
<li><a href="https://docs.microsoft.com/ja-jp/azure/databricks/delta/" target="_blank" rel="noopener noreferrer">Delta Engine および Delta Lake ガイド</a></li>
<li><a href="https://aws.amazon.com/blogs/big-data/build-a-lake-house-architecture-on-aws/" target="_blank" rel="noopener noreferrer">Build a Lake House Architecture on AWS</a></li>
<li><a href="https://aws.amazon.com/blogs/big-data/harness-the-power-of-your-data-with-aws-analytics/" target="_blank" rel="noopener noreferrer">Harness the power of your data with AWS Analytics</a></li>
<li><a href="https://aws.amazon.com/blogs/architecture/how-to-accelerate-building-a-lake-house-architecture-with-aws-glue/" target="_blank" rel="noopener noreferrer">How to Accelerate Building a Lake House Architecture with AWS Glue</a></li>
</ol>
<section data-footnotes="" class="footnotes"><h2 id="footnote-label" class="sr-only">Footnotes</h2>
<ol>
<li id="user-content-fn-zorder">
<p>余談だが私の修士の研究では Z-order で局所性を考慮したアプローチをしていたので思い入れがある <a href="/posts/understanding-data-lakehouse#user-content-fnref-zorder">↩</a></p>
</li>
<li id="user-content-fn-bq-export">
<p><a href="https://cloud.google.com/bigquery/docs/exporting-data#exporting_data_stored_in" target="_blank" rel="noopener noreferrer">SQL による書き込みは可能</a> <a href="/posts/understanding-data-lakehouse#user-content-fnref-bq-export">↩</a></p>
</li>
</ol>
</section></div></article></div><footer class="site-footer"><div class="content-wrapper"><p>© <!-- -->ttyfky</p></div></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"slug":"understanding-data-lakehouse","postData":{"id":"understanding-data-lakehouse","contentHtml":"\u003ch1 id=\"overview\"\u003eOverview\u003c/h1\u003e\n\u003cp\u003e本記事では Data Lakehouse という概念についての調査メモ。\nLakehouse は Databrics が提唱している概念のようで、特定のベンダーが進めている話ならまだ重要視するほどでもなさそうだが\n\u003ca href=\"http://cidrdb.org/cidr2021/papers/cidr2021_paper17.pdf\"\u003e論文\u003c/a\u003eとしても出ており、\nGCP でも紹介され(\u003ca href=\"https://cloud.google.com/blog/ja/products/data-analytics/open-data-lakehouse-on-google-cloud\"\u003e2021-10-29\u003c/a\u003e,\n\u003ca href=\"https://cloud.google.com/blog/ja/products/data-analytics/google-cloud-data-cloud-summit\"\u003e2022-04-05\u003c/a\u003e)、\nつい最近発表された \u003ca href=\"https://cloud.google.com/bigquery/docs/biglake-intro\"\u003eBigLake\u003c/a\u003e\nというプロダクトが作られる元となった考え方のようなので 2022-04 時点で Lakehouse はどういったものを指しどんな課題を解こうとしているのかということを整理する。\u003c/p\u003e\n\u003ch2 id=\"tldr\"\u003eTL;DR\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eこれまでのデータ処理基盤は\u003ca href=\"building-data-platform\"\u003e以前触れた\u003c/a\u003e通り、Datalake -\u003e Data Warehouse(DWH) -\u003e Datamart のようなアーキテクチャが一般的\u003c/li\u003e\n\u003cli\u003e従来の DWH や Datalake では分析や機械学習を行うためにはそれぞれ一定の制限がある\u003c/li\u003e\n\u003cli\u003eData Lakehouse は DWH や Datalake の良い点を活かして既存の制限を解決するアプローチ\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e本記事では論文 \u003ca href=\"http://cidrdb.org/cidr2021/papers/cidr2021_paper17.pdf\"\u003eLakehouse: A New Generation of Open Platforms that Unify Data Warehousing and Advanced Analytics\u003c/a\u003e (Ref1) での議論をベースに整理する。\u003c/p\u003e\n\u003ch1 id=\"従来のデータ分析基盤について\"\u003e従来のデータ分析基盤について\u003c/h1\u003e\n\u003cp\u003e従来のデータ活用においては RDB などから必要なデータを取り出して構造化データを DWH として取り込む形が早くから始まった。\u003cbr\u003e\nDWH は BI アプリケーションから扱いやすいが、 ML でのデータ活用ではテキスト、画像、動画、音声などの非構造化データを扱う需要があり、 DWH でのデータの持ち方では扱いづらい場面がある。\u003c/p\u003e\n\u003cp\u003eそこで、生データを扱い非構造化データの保持も可能なものとして Datalake という層を作り、非構造化データを扱う処理は Datalake を利用することで処理が可能となった。\nしかし、Datalake はデータの管理が複雑で、トランザクション、データ品質の保証・一貫性・分離性などが欠如しており、データ処理パイプラインにおいてデータの追加と読み取りの同時実行などが難しいという制限がある。\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://databricks.com/wp-content/uploads/2020/01/data-lakehouse-new-1024x538.png\" alt=\"Datalakehouse Image\"\u003e\u003cbr\u003e\n(Ref2 より)\u003c/p\u003e\n\u003ch2 id=\"従来のデータウェアハウスアーキテクチャの課題\"\u003e従来のデータウェアハウスアーキテクチャの課題\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eDWH は構造化データの利用には良いが非構造化データの利用には向いていない\u003c/li\u003e\n\u003cli\u003e機械学習を行う場合非構造化データを用いる場合もあるため DWH だけでは不十分\u003c/li\u003e\n\u003cli\u003e生データが前提の Datalake の概念によりではあらゆるデータを保持できるようになったが、データ処理パイプラインの作り方に制限がある\n\u003cul\u003e\n\u003cli\u003eトランザクションは管理できない\u003c/li\u003e\n\u003cli\u003eデータ品質の保証の仕組みは無視されがち\n\u003cul\u003e\n\u003cli\u003eデータの重複など\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e異なる DWH にデータが有る場合にデータの移動が必要となる\u003c/li\u003e\n\u003cli\u003eDatalake と DWH を分離したアーキテクチャでの複雑性\n\u003cul\u003e\n\u003cli\u003eそれぞれでセマンティクスの異なるデータタイプ\u003c/li\u003e\n\u003cli\u003eSQL の方言の違い\u003c/li\u003e\n\u003cli\u003eデータのスキーマが異なる\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eデータの鮮度\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"lakehouse\"\u003eLakehouse\u003c/h1\u003e\n\u003ch2 id=\"lakehouse-の目指すもの\"\u003eLakehouse の目指すもの\u003c/h2\u003e\n\u003cp\u003eLakehouse は、Datalake と Data Warehouse の優れた部分を組み合わせた、新しくオープンなアーキテクチャである。標準化されたシステムによって実現され DWH と同様のデータ構造とデータマネジメント機構を備えており、 Datalake のように安価なストレージに直接アクセスすることができる。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDatalake において信頼できるデータマネジメントが可能\n\u003cul\u003e\n\u003cli\u003eDatalake のレイヤーにおいてもトランザクションや ID の管理が可能\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eML とデータサイエンスをサポート\n\u003cul\u003e\n\u003cli\u003eML の仕組みがファイルの直接読み込む事が可能\u003c/li\u003e\n\u003cli\u003eDataFrames のようにデータを抽象化して操作が可能\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eSQL のパフォーマンス\n\u003cul\u003e\n\u003cli\u003eParquet や ORC のようなデータフォーマットを扱える\u003c/li\u003e\n\u003cli\u003e直接データアクセス可能\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"lakehouse-が持つべきと考えられる機能\"\u003eLakehouse が持つべきと考えられる機能\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eトランザクションのサポート\n\u003cul\u003e\n\u003cli\u003e同時にデータの読み書きを行うデータパイプラインを許容するため ACID トランザクションをサポートし、特に SQL を用いたケースで複数のデータの読み書きがあったとしても一貫性の維持が可能\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eスキーマ適用及びガバナンス可能\n\u003cul\u003e\n\u003cli\u003eスタースキーマ、スノーフレークスキーマのようにデータウェアハウスのスキーマアーキテクチャをサポートすることでレイクハウスはスキーマの適用・進化をサポート\u003c/li\u003e\n\u003cli\u003eシステムはデータの完全性を保証し、頑健性のあるガバナンス機能や監査機構が可能\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eBI のサポート\n\u003cul\u003e\n\u003cli\u003eソースデータに直接アクセスして BI が可能で、遅延を減らしデータの鮮度が保つ\u003c/li\u003e\n\u003cli\u003eデータレイクとデータウェアハウスでデータの二重持ちする必要が無いためコストを低減\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e計算リソースとストレージの分離\n\u003cul\u003e\n\u003cli\u003eストレージと計算リソースが異なるクラスターを用いることで同時接続ユーザー数の増加やデータ量の増加に応じてシステムをスケールアウト\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eオープンなストレージフォーマット\n\u003cul\u003e\n\u003cli\u003e使用するストレージフォーマットは Parquet のようにオープンかつ標準化されたもの\n\u003cul\u003e\n\u003cli\u003eTensorFlow や Spark MLlib は Parquet を読むことができるため、メタデータにクエリしどの Parquet ファイルを読むかの管理を行うだけで良い\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e機械学習、Python/R ライブラリのように多くのツールやエンジンに対する API を提供しデータへの直接アクセスが可能\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e様々なデータタイプをサポート\n\u003cul\u003e\n\u003cli\u003e画像、動画、音声、準構造化データ、テキストを含む、新たなデータアプリケーションで必要となる様々なデータタイプの分析・精錬・格納に利用\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e様々なワークロードをサポート\n\u003cul\u003e\n\u003cli\u003eデータサイエンス、機械学習、SQL や分析に対応\u003c/li\u003e\n\u003cli\u003e全て同じデータリポジトリを使用\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eエンドツーエンドのストリーミング\n\u003cul\u003e\n\u003cli\u003eストリーミングのサポートによりリアルタイムデータ処理専用のアプリケーションを別に持つ必要がなくなる\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"lakehouse-のアーキテクチャ\"\u003eLakehouse のアーキテクチャ\u003c/h2\u003e\n\u003cp\u003eLakehouse は低コストで直接アクセス可能なストレージに基づくデータ管理システムであり、ACID トランザクションやインデックスなど従来の分析型 DBMS の管理・パフォーマンス機能も備えるようにしたい。\nデータの直接アクセスが可能なためデータの独立性は放棄する。\u003c/p\u003e\n\u003cp\u003eデータはオブジェクトストレージ上で Parquet のような標準化されたフォーマットで持ち、トランザクションのサポートのためにメタデータレイヤーを持つ。\nDataFrames を利用できる API を持つことで R や Python の Pandas との連携が簡単にでき、また Spark SQL では宣言的に利用でき遅延実行できる。\u003c/p\u003e\n\u003cfigure\u003e\n\u003cimg src=\"lakehouse-architecture-sample.png\" alt=\"Lakehouseのアーキテクチャイメージ図\"\u003e\n\u003c/figure\u003e\n(Ref1 より引用）\n\u003ch3 id=\"データ管理のためのメタデータレイヤー\"\u003eデータ管理のためのメタデータレイヤー\u003c/h3\u003e\n\u003cp\u003eLakehouse として最初に必要になるの Datalake ストレージのためのはメタデータレイヤーである。\n具体的には、\u003ca href=\"https://iceberg.apache.org/\"\u003eApache Iceberg\u003c/a\u003e や \u003ca href=\"https://hudi.apache.org/\"\u003eApache Hudi\u003c/a\u003e、\u003ca href=\"https://delta.io/\"\u003eDelta Lake\u003c/a\u003e などの\nファイルストレージ上に保存された Parquet/ORC フォーマットのファイルの管理を可能にするメカニズムを用いて、ACID トランザクションやバージョン管理などを可能にする。\u003c/p\u003e\n\u003cp\u003eこの領域は比較的新しく、今後更に最適化が進む可能性がある。挙げられたフレームワークもトランザクションログは 1 テーブルのみをサポートしているなど、高遅延であったり、ファイルが大きくなるといったオブジェクトストレージの制限の影響を受けている。\u003c/p\u003e\n\u003ch3 id=\"lakehouse-における-sql-パフォーマンス\"\u003eLakehouse における SQL パフォーマンス\u003c/h3\u003e\n\u003cp\u003eDatalake における最も大きな技術的な課題は、データの独立性を放棄した(直接アクセス可能なファイルで管理するため)上でどの様に SQL の最高のパフォーマンスを実現するのかという点である。\u003c/p\u003e\n\u003cp\u003eSQL パフォーマンスを良くするアプローチとしては以下が考えられる。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCaching\n\u003cul\u003e\n\u003cli\u003eトランザクションのメタデータを処理ノードの SSD や RAM に置く\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e補助データ\n\u003cul\u003e\n\u003cli\u003eカラム毎の最大最小値の統計情報を各ファイルごとに持つ\u003c/li\u003e\n\u003cli\u003eBloom filter ベースのインデックスを構築し選択した列でデータをスキップできるようにする\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eデータの配置\n\u003cul\u003e\n\u003cli\u003eZ-order\u003csup\u003e\u003ca href=\"#user-content-fn-zorder\" id=\"user-content-fnref-zorder\" data-footnote-ref=\"\" aria-describedby=\"footnote-label\"\u003e1\u003c/a\u003e\u003c/sup\u003e などを用いてデータの局所性を表現する\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e直接アクセス可能で長期的にデータの保存が可能かつ高パフォーマンスな Lakehouse の仕組みの設計は現状も課題である。\n将来的にはこのユースケースに特化した新たなデータフォーマットの自体が必要かもしれないが、それを抜きにしてもここで上げたパフォーマンスを良くするための要素はいずれも向上の余地はある。\u003c/p\u003e\n\u003ch1 id=\"クラウドベンダーにおける-lakehouse\"\u003eクラウドベンダーにおける Lakehouse\u003c/h1\u003e\n\u003ch2 id=\"biglake---gcp\"\u003eBigLake - GCP\u003c/h2\u003e\n\u003cp\u003eLakehouse の調査をするきっかけになったのは Apr2022 の Google Data Cloud Summit 先駆けて \u003ca href=\"https://cloud.google.com/blog/ja/products/data-analytics/google-cloud-data-cloud-summit\"\u003eBigLake についての記事\u003c/a\u003eが発表されたからだった。\u003c/p\u003e\n\u003cp\u003e記事の執筆時点では Preview 版であるが、 \u003ca href=\"https://cloud.google.com/bigquery/docs/biglake-intro\"\u003eIntroduction to BigLake tables\u003c/a\u003e に BigLake の説明がある。\u003cbr\u003e\n簡単に表現すると BigLake は BigQuery External Table 機能の拡張のようなものだ。\n基本的には BigQuery (以下 BQ) をインターフェイスとして、GCS や S3 などのオブジェクトストレージへアクセスするが、BQ がアクセスマネジメントを抽象化する。\nつまり、ユーザーのアクセス権限は BQ のテーブルに対してのみ考えたら良く、BQ を超えたレイヤー(i.e. 外部のストレージ)に対するアクセス権限をユーザーは意識する必要がない。\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://cloud.google.com/bigquery/images/biglake_arch.png\" alt=\"BigLake Image\"\u003e\u003cbr\u003e\n(Ref4 より引用）\u003c/p\u003e\n\u003cp\u003e現状はトランザクションへの言及などはなく、非構造化データとの連携もこの形で行いやすくなるとも思えないため、自分の理解ではこれまで触れてきた Lakehouse の目標には届いていない印象。\nBQ の場合はそもそも Dataflow や Serverless Spark 等の ETL のレイヤーから低遅延の Storage API を提供してデータを素早くよしなに扱って欲しいという思惑があるかもしれない。\u003c/p\u003e\n\u003cp\u003eまた、BQ は\u003ca href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/transactions\"\u003eトランザクションのサポート\u003c/a\u003eが Preview レベルではあるが開始されているため、\n今後外部テーブル関しての操作自体\u003csup\u003e\u003ca href=\"#user-content-fn-bq-export\" id=\"user-content-fnref-bq-export\" data-footnote-ref=\"\" aria-describedby=\"footnote-label\"\u003e2\u003c/a\u003e\u003c/sup\u003eやトランザクション機能の追加があると Lakehouse の実現に近づくと思う。\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/ja/products/data-analytics/getting-started-with-new-table-formats-on-dataproc\"\u003eDataproc の新しいテーブル形式を使ってみる\u003c/a\u003eや\n\u003ca href=\"https://cloud.google.com/blog/topics/developers-practitioners/how-build-open-cloud-datalake-delta-lake-presto-dataproc-metastore\"\u003eHow to build an open cloud datalake with Delta Lake, Presto \u0026#x26; Dataproc Metastore\u003c/a\u003e などの記事にもある通り、\nGCP 上での Delta Lake や Apache Iceberg の利用も可能だが、Dataproc (i.g. Hadoop) で Spark の利用が前提になっている。\nSpark/Hadoop クラスタの運用は手間がかかるので、Serverless Spark が GA とったことはこれらのフレームワークを利用する上でも良い発展に思える。\u003c/p\u003e\n\u003ch2 id=\"delta-lake---azure\"\u003eDelta Lake - Azure\u003c/h2\u003e\n\u003cp\u003eAzure は Databrics と連携しており、Delta Lake についての\u003ca href=\"https://docs.microsoft.com/ja-jp/azure/databricks/delta/\"\u003e厚めのドキュメント\u003c/a\u003eがある。\u003cbr\u003e\n日本語で細かく説明したドキュメントは貴重なので一読の価値あり。\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://docs.microsoft.com/ja-jp/azure/databricks/scenarios/media/what-is-azure-databricks/azure-databricks-overview.png\" alt=\"Azure Databrics\"\u003e\u003cbr\u003e\n(Ref6 より引用）\u003c/p\u003e\n\u003ch2 id=\"aws\"\u003eAWS\u003c/h2\u003e\n\u003cp\u003eAWS では \u003ca href=\"https://aws.amazon.com/blogs/big-data/build-a-lake-house-architecture-on-aws/\"\u003eBuild a Lake House Architecture on AWS\u003c/a\u003e、\n\u003ca href=\"https://aws.amazon.com/blogs/big-data/harness-the-power-of-your-data-with-aws-analytics/\"\u003eHarness the power of your data with AWS Analytics\u003c/a\u003e、\n\u003ca href=\"https://aws.amazon.com/blogs/architecture/how-to-accelerate-building-a-lake-house-architecture-with-aws-glue/\"\u003eHow to Accelerate Building a Lake House Architecture with AWS Glue\u003c/a\u003e\nなど、AWS 上で Lakehouse を構築する方法を説明した記事が多く見つかった。\u003c/p\u003e\n\u003cp\u003e中でも \u003ca href=\"https://aws.amazon.com/lake-formation/\"\u003eAWS Lake Formation\u003c/a\u003e は Lakehouse 構築のためのキーとなるプロダクトに見え、S3 のファイルに対して ACID トランザクションを実現したりクエリによるアクセス速度の向上を実現でき、\n論文中で言及していたデータ管理のためのメタデータレイヤーを構築を可能にする。\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://d2908q01vomqb2.cloudfront.net/b6692ea5df920cad691c20319a6fffd7a4a766b8/2020/12/08/harness-the-power-4.jpg\" alt=\"AWS Lakehouse Architecture\"\u003e\u003cbr\u003e\n(Ref9 より引用）\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://d2908q01vomqb2.cloudfront.net/fc074d501302eb2b93e2554793fcaf50b3bf7291/2021/08/18/Fig2-Glue.png\" alt=\"AWS Lakehouse Architecture\"\u003e\n(Ref10 より引用）\u003c/p\u003e\n\u003ch1 id=\"終わりに\"\u003e終わりに\u003c/h1\u003e\n\u003cp\u003e本記事では Data Lakehouse の調査を行った。\u003c/p\u003e\n\u003cp\u003eLakehouse は従来の DWH や Datalake の仕組みに存在した制限を乗り越えるためのアプローチである。\u003cbr\u003e\nDatalake は ACID トランザクションやインデックス等の DBMS のような仕組みを用いていたり、Parquet/OCR のような標準化されたファイルフォーマットを用いての直接ファイルアクセスが可能なことが期待される。\u003c/p\u003e\n\u003cp\u003e各クラウドベンダーもそれぞれ Lakehouse に言及しており、今後のデータ処理基盤構築では意識していくべきものに思える。\nLakehouse の実現には Dalta Lake のようなフレームワークを用いるか、各クラウドベンダーが提供するプロダクトを用いると良さそうだが、ベンダー毎に実現可能なレベル感はまだ一定ではなく、今後の継続的なアップデートが期待される。\u003c/p\u003e\n\u003ch1 id=\"references\"\u003eReferences\u003c/h1\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"http://cidrdb.org/cidr2021/papers/cidr2021_paper17.pdf\"\u003eLakehouse: A New Generation of Open Platforms that Unify Data Warehousing and Advanced Analytics\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://databricks.com/blog/2020/01/30/what-is-a-data-lakehouse.html\"\u003eWhat Is a Lakehouse?\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://cloudonair.withgoogle.com/events/summit-data-cloud-2022/watch?talk=s_databricks\"\u003eRise of the Data Lakehouse in Google Cloud\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://cloud.google.com/bigquery/docs/biglake-intro\"\u003eIntroduction to BigLake tables\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://cloudonair.withgoogle.com/events/summit-data-cloud-2022/watch?talk=vod_da1_s1_big_lake\"\u003eBigLake: Unify data warehouses and lakes with Google Cloud\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://docs.microsoft.com/ja-jp/azure/databricks/scenarios/what-is-azure-databricks-ws\"\u003eDatabricks Data Science \u0026#x26; Engineering とは\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://docs.microsoft.com/ja-jp/azure/databricks/delta/\"\u003eDelta Engine および Delta Lake ガイド\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://aws.amazon.com/blogs/big-data/build-a-lake-house-architecture-on-aws/\"\u003eBuild a Lake House Architecture on AWS\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://aws.amazon.com/blogs/big-data/harness-the-power-of-your-data-with-aws-analytics/\"\u003eHarness the power of your data with AWS Analytics\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://aws.amazon.com/blogs/architecture/how-to-accelerate-building-a-lake-house-architecture-with-aws-glue/\"\u003eHow to Accelerate Building a Lake House Architecture with AWS Glue\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003csection data-footnotes=\"\" class=\"footnotes\"\u003e\u003ch2 id=\"footnote-label\" class=\"sr-only\"\u003eFootnotes\u003c/h2\u003e\n\u003col\u003e\n\u003cli id=\"user-content-fn-zorder\"\u003e\n\u003cp\u003e余談だが私の修士の研究では Z-order で局所性を考慮したアプローチをしていたので思い入れがある \u003ca href=\"#user-content-fnref-zorder\" data-footnote-backref=\"\" class=\"data-footnote-backref\" aria-label=\"Back to content\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"user-content-fn-bq-export\"\u003e\n\u003cp\u003e\u003ca href=\"https://cloud.google.com/bigquery/docs/exporting-data#exporting_data_stored_in\"\u003eSQL による書き込みは可能\u003c/a\u003e \u003ca href=\"#user-content-fnref-bq-export\" data-footnote-backref=\"\" class=\"data-footnote-backref\" aria-label=\"Back to content\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/section\u003e","title":"Data Lakehouse を理解する","date":"2022-04-10","tags":["data","dwh","lakehouse"],"description":"Data Lakehouse についての概要説明とクラウドベンダーごとのアプローチについて","published":true,"engineering":true}},"__N_SSG":true},"page":"/posts/[slug]","query":{"slug":"understanding-data-lakehouse"},"buildId":"Omp03XJcnyDL6FY7ABKPf","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>